<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<meta name="description" content="description" />
	<meta name="keywords" content="keywords" />
	<meta name="author" content="author" />
	<style>
		table {
			font-family: arial, sans-serif;
			border-collapse: collapse;
			width: 100%;
		}

		td,
		th {
			border: 1px solid #dddddd;
			padding: 8px;
		}

		tr:nth-child(even) {
			background-color: #cdcdcd;
		}
	</style>
	<link rel="stylesheet" type="text/css" href="../default.css" media="screen" />
	<title>Nick Wang at NCTU</title>
</head>

<body>

	<div class="outer-container">

		<div class="inner-container">

			<div class="header">

				<div class="title">
					<span class="sitename"><a href="../index.html">Assistive Robotics Group</a>&nbsp;&nbsp;&nbsp;<a
							href="../index_ch.html">機器人與輔助科技實驗室</a></span>
				</div>

			</div>

			<div class="path">

				<a href="../index.html">Home</a>
				<a href="../event.html">News</a>
				<a href="../people.html">People</a>
				<a href="../robots.html">Robots</a>
				<a href="../research.html">Research</a>
				<a href="../publications.html">Publications</a>
				<a href="../courses.html">Courses</a>
				<a href="../materials.html">Materials</a>
			</div>

			<div class="blank">
				<div class="wrapper-center">
					<h0 style="text-align: center">
						Enabling Learning-based Navigation in Obscurants with Lightweight, Low-cost Millimeter Wave
						Radar Using Cross-modal Contrastive Learning of Representations
					</h0>
				</div>
				<br><br>

				<div class="wrapper-center">
					<button onclick="window.open('http://github.com/huangjuite/radar-navigation')"
						class="button button-gray">Github</button>
					<button onclick="location.href='#datasets'" class="button button-gray">Dataset</button>
					<button class="button button-gray">arXiv:comming soon</button>
				</div>

				<h1>Abstract</h1>
				<p>

					Deep reinforcement learning (RL) has shown remarkable success on a variety of tasks to learn from
					mistakes. To learn collision-free policies for unmanned vehicles, deep RL has been trained with
					various data modalities including RGB, depth images, LiDAR point clouds without the use of classic
					map-localize-plan approaches.
					However, existing methods suffer from degraded sensing conditions, such as smoke and other
					obscurants, that impair observations from camera and LiDAR.
					We propose to enable learning-based autonomous navigation with single-chip lightweight, low-cost
					millimeter-wave (mmWave) radars. Given that the mmWave radar signals are often noisy and sparse, we
					proposed cross-modal contrastive learning for representation (CM-CLR) by maximizing the agreements
					between mmWave radar and LiDAR signals in training stage. We carried out real robot quantitative
					evaluations, and compared with 1) a method with two separate networks using cross-modal generative
					reconstruction and RL policy, and 2) a baseline RL policy without cross-modal representation. We
					showed that the proposed end-to-end deep RL policy with contrastive learning successfully navigate
					the robot through smoke-filled maze environments, and demonstrated superior performance than
					generative reconstruction that sometimes produced noise artifact walls or obstacles. We also
					demonstrated CM-CLR method on a resource-constrained LoCoBot, and all pre-trained models and
					hardware settings are openly available for reproducibility at
					<a
						href='https://arg-nctu.github.io/projects/deeprl-mmWave.html'>https://arg-nctu.github.io/projects/deeprl-mmWave.html</a>.
				</p>

				<div class="wrapper-center">
					<img src="img/teaser-mmrl.png" alt="hdf5-example" height="250">
				</div>




				<h1>Video</h1>
				<p></p>
				<div class="container" align="middle">
					<iframe src="https://player.vimeo.com/video/468839536" width="640" height="360" frameborder="0"
						allow="autoplay; fullscreen" allowfullscreen></iframe>
				</div>


				<h1 id="datasets">Datasets</h1>
				<h2>
					<ul style="margin-left: 40px">
						<li style="list-style:circle; font-size:20px">rosbag</li>
						<p>The original recorded format. All data are recorded in realtime. If user are familiar with
							ROS. There is <a href="http://wiki.ros.org/rosbag">rosbga API</a> to extract data from bags
							or using <a href="http://wiki.ros.org/rosbag/Commandline">commandline</a> to play data in
							realtime. <a href="http://wiki.ros.org/rviz">Rviz</a> can help the visualization.
							<br><br>
							<a
								href="https://drive.google.com/drive/folders/1KSccVqYDShI_Acfk8F4k_N76aVVPdN4o?usp=sharing">click
								here to download all rosbags.</a>
						</p>

						<li style="list-style:circle; font-size:20px">hdf5</li>
						<p>Data in rosbags has been transfer to numpy arrays, stored in hdf5 format and
							organized to 5Hz framerate. Including following data:
							<li style="list-style:circle;margin-left: 40px">LiDAR <br> 3D point cloud <br>1D range
							</li>
							<li style="list-style:circle;margin-left: 40px">mmWave radar <br> 3D point cloud <br>1D
								range</li>
							<li style="list-style:circle;margin-left: 40px">human demonstration action</li>
							<li style="list-style:circle;margin-left: 40px">wheel oddmetry</li>
							<br>
							User can use <a href="https://github.com/ganymede42/h5pyViewer">h5pyViewer</a> to check the
							data.
							<br>
						<div class="wrapper-center">
							<img src="img/hdf5-example.png" alt="hdf5-example" height="300">
						</div>

						<br><br>
						<a href="https://drive.google.com/drive/u/1/folders/10W1_F36Ew2dd1L2lq8xgZyIHGZCsMBit">click
							here to download all hdf5 data</a>
						</p>

						<li style="list-style:circle; font-size:20px">pickle</li>
						<p>
							Data in hdf5 dataset has been re-organized to transition style and calculated the reward
							inorder to train RL
							algorithm. Every pkl file contain 512 frame of transition data. Each transition contains the
							following data.
							<li style="list-style:circle;margin-left: 40px">mm_scan</li>
							<li style="list-style:circle;margin-left: 40px">laser_scan</li>
							<li style="list-style:circle;margin-left: 40px">pos_diff</li>
							<li style="list-style:circle;margin-left: 40px">action</li>
							<li style="list-style:circle;margin-left: 40px">reward</li>
							<li style="list-style:circle;margin-left: 40px">next_mm_scan</li>
							<li style="list-style:circle;margin-left: 40px">next_laser_scan</li>
							<li style="list-style:circle;margin-left: 40px">next_pos_diff</li>
							<br><br>
							<a href="https://drive.google.com/drive/u/1/folders/1FMkjvJl070_LxqcNBFeBedPsZFoy0VNe">click
								here to download all transition data</a>
						</p>

						<li style="list-style:circle; font-size:20px">demo of reconstruction</li>
						<p>range were ploted on cartesian coordinate system</p>
						<div class="wrapper-center">
							<img src="img/demo.png" alt="hdf5-example" height="500">
						</div>

						<li style="list-style:circle; font-size:20px">All data</li>
						<div class="wrapper-center">
							<iframe
								src="https://docs.google.com/spreadsheets/d/e/2PACX-1vQobaKmi7cr2O4abUyIKbkUFovtQmjz6AFpLUb6LX53qvBen18g5iMI6KiQR9HSEDPOaT6cchKyOi1-/pubhtml?gid=1072056062&amp;single=true&amp;widget=true&amp;headers=false"
								width="611" height="910" frameborder="">
							</iframe>
						</div>
					</ul>
				</h2>



				<div class="clearer">&nbsp;</div>

			</div>

			<div class="footer">

				<span class="left">
					&copy; H.C. Wang
				</span>

				<!-- <span class="right"><a href="http://templates.arcsin.se/">Website template</a> by <a
						href="http://arcsin.se/">Arcsin</a></span> -->

				<div class="clearer"></div>

			</div>

		</div>

	</div>

</body>

</html>