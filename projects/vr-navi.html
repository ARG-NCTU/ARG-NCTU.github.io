<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<meta name="description" content="description" />
	<meta name="keywords" content="keywords" />
	<meta name="author" content="author" />
	<style>
		table {
			font-family: arial, sans-serif;
			border-collapse: collapse;
			width: 100%;
		}

		td,
		th {
			border: 1px solid #dddddd;
			padding: 8px;
		}

		tr:nth-child(even) {
			background-color: #cdcdcd;
		}
	</style>
	<link rel="stylesheet" type="text/css" href="../default.css" media="screen" />
	<title>Nick Wang at NCTU</title>
</head>

<body>

	<div class="outer-container">

		<div class="inner-container">

			<div class="header">

				<div class="title">
					<span class="sitename"><a href="../index.html">Assistive Robotics Group</a>&nbsp;&nbsp;&nbsp;<a
							href="../index_ch.html">機器人與輔助科技實驗室</a></span>
				</div>

			</div>

			<div class="path">

				<a href="../index.html">Home</a>
				<a href="../event.html">News</a>
				<a href="../people.html">People</a>
				<a href="../robots.html">Robots</a>
				<a href="../research.html">Research</a>
				<a href="../publications.html">Publications</a>
				<a href="../courses.html">Courses</a>
				<a href="../materials.html">Materials</a>
			</div>

			<div class="blank">
				<div class="wrapper-center">
					<h0 style="text-align: center">
						An Evaluation Framework of Human-Robot Teaming for Navigation among Movable Obstacles via Virtual Reality-based Interactions
					</h0>
					<h2>
                        Ching-I Huang, Sun-Fu Chou, Li-Wei Liou, Quang TN Vo, Nathan, Yu-Ting Ko, Lap-Fai Yu, and Hsueh-Cheng Wang
					</h2>
				<br><br>
				</div>
				<!--
				<div class="wrapper-center">
					<button onclick="window.open('https://github.com/ARG-NCTU/handover_grasping')"
						class="button button-gray">Interface</button>
					<button onclick="window.open('https://github.com/ARG-NCTU/handover-system')"
						class="button button-gray">System</button>
				</div>-->

				<h1>Abstract</h1>
				<p>
					In recent decades, robots are capable of assisting or carrying out the works human cannot in the hazardous areas,
                    such work frequently aligned with search-and-rescue missions in the Defense Advanced Research Projects Agency (DARPA)
                    Subterranean (SubT) Challenge. Although many autonomy techniques have been developed and demonstrated in the
                    competition, some of the complex situations and operations still require experienced decisions from human that the robots are
                    not allowed to execute without the supervision. It is still an open question how to effectively test and support the development
                    of the heterogeneous multi-robot team that requires human interactions. Our work propose a simulation framework that
                    the human supervisor uses a commercial virtual reality (VR) interfaces while stationed at the base. The robot team, two
                    unmanned ground vehicles (one is twice as fast as the other which is equipped a robot arm) located remotely, performs
                    search and rescue in a navigation among movable objects(NAMO) scenario where navigation path may be blocked by
                    movable obstacles that require additional a manipulator to push them away. We carried out behavioral studies of 24
                    users participated in this study and they were tested under the proposed virtual environments of Unity and Gazebo evaluation
                    framework. We showed that the proposed framework is cost-effective and well-suited for human interactions including: 1)
                    the efficiency of single-user control of multiple heterogeneous robots with that of multi-user control of multiple heterogeneous
                    robots, and 2) the collaborative navigation by users and multiple heterogeneous robots with autonomous algorithms (navigation-
                    only vs. capabilities to push-away obstacles), which affect the user’s strategy
				</p>

				<div class="wrapper-center">
					<img src="img/vr_navi_teaser.png" alt="teaser" height="400">
				</div>

 
				<h1>Video</h1>
				<p></p>
				<div class="container" align="middle">
					<iframe title="vimeo-player" src="https://player.vimeo.com/video/813752888?h=18f53125e9" width="640" height="360" frameborder="0" allowfullscreen></iframe>
				</div> 
 			
<!--					<h1>Bibtex</h1>
				<div 
				style="background-color:rgb(212, 212, 212);
				color:rgb(0, 0, 0); 
				padding:15px;
				width: 680px;
				border: 1px solid rgb(0, 0, 0);;
				margin: 30px;">
				<p>
				@ARTICLE{zocco-2023-efficient-marine-debris , <br>
					author={Zocco, Federico and Lin, Tzu-Chieh and Huang, Ching-I and Wang, Hsueh-Cheng and Khyam, Mohammad Omar and Van, Mien}, <br>
					journal={IEEE Robotics and Automation Letters},  <br>
					title={Towards More Efficient EfficientDets and Real-Time Marine Debris Detection},  <br>
					year={2023}, <br>
					volume={8}, <br>
					number={4}, <br>
					pages={2134-2141}, <br>
					doi={10.1109/LRA.2023.3245405} <br>
				}
					<br>
				</p>
			  	</div> 

				<h1>Acknowledgments</h1>
				<p>
					This work was supported by the Natural Environment Research Council, United Kingdom [grant number NE/V008080/1] and by Taiwan’s National
					Science and Technology Council (grants 111-NU-E-A49-001-NU, 110-2221-E-A49-124, and 111-2623-E-A49-007). This work was funded in part by 
					Qualcomm through the Taiwan University Research Collaboration Project. (Corresponding author: Mien Van)
				</p>

			</div>
-->
			<div class="footer">

				<span class="left">
					&copy; H.C. Wang
				</span>

				<!-- <span class="right"><a href="http://templates.arcsin.se/">Website template</a> by <a
						href="http://arcsin.se/">Arcsin</a></span> -->

				<div class="clearer"></div>

			</div>

		</div>

	</div>

</body>

</html>
