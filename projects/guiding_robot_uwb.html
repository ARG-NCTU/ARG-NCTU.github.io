<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<meta name="description" content="description" />
	<meta name="keywords" content="keywords" />
	<meta name="author" content="author" />
	<style>
		table {
			font-family: arial, sans-serif;
			border-collapse: collapse;
			width: 100%;
		}

		td,
		th {
			border: 1px solid #dddddd;
			padding: 8px;
		}

		tr:nth-child(even) {
			background-color: #cdcdcd;
		}
	</style>
	<link rel="stylesheet" type="text/css" href="../default.css" media="screen" />
	<title>Nick Wang at NCTU</title>
</head>

<body>

	<div class="outer-container">

		<div class="inner-container">

			<div class="header">

				<div class="title">
					<span class="sitename"><a href="../index.html">Assistive Robotics Group</a>&nbsp;&nbsp;&nbsp;<a
							href="index_ch.html">機器人與輔助科技實驗室</a></span>
				</div>

			</div>

			<div class="path">

				<a href="../index.html">Home</a>
				<a href="../event.html">News</a>
				<a href="../people.html">People</a>
				<a href="../robots.html">Robots</a>
				<a href="../research.html">Research</a>
				<a href="../publications.html">Publications</a>
				<a href="../courses.html">Courses</a>
				<a href="../materials.html">Materials</a>
			</div>

			<div class="blank">
				<h0>Assistive Navigation using Deep Reinforcement Learning Guiding Robot with UWB Beacons and Semantic Feedbacks for Blind and Visually Impaired People</h0>
				<p></p>

				<h1>Abstract</h1>
				<p>
					Facilitating navigation in pedestrian environments is critical for enabling people who are blind and visually impaired (BVI) to achieve independent mobility. A deep-reinforcement-learning-based assistive guiding robot with ultrawide-bandwidth (UWB) beacons that can navigate through routes with designated waypoints was designed in this study. Typically, a simultaneous localization and mapping (SLAM) framework is used to estimate the robot pose and navigational goal; however, SLAM frameworks are vulnerable in certain dynamic environments. The proposed navigation method is a learning approach based on state-of-the-art deep reinforcement learning and can effectively avoid objects. When used with UWB beacons, the proposed strategy is suitable for environments with dynamic pedestrians. We also designed a harness device with an audio interface that enables BVI users to interact with the guiding robot through intuitive feedback. The UWB beacons were installed with an audio interface to obtain environmental information The on-harness and on-beacon verbal feedback provides information on points-of-interest (POI) and turn-by-turn information to BVI users. BVI users were recruited in this study to conduct navigation tasks in different scenarios. A route was designed in a simulated ward to represent daily activities. In real-world situations, SLAM-based state estimation might be affected by dynamic obstacles, and the visual-based trail may suffer from occlusions from pedestrians or other obstacles. The proposed system successfully navigated through environments with dynamic pedestrians, in which systems based on existing SLAM algorithms have failed.
				</p>

				<h1>Teaser</h1>
				<p></p>
				<div class="container" align="middle">
					<!-- <iframe src="https://player.vimeo.com/video/501143422" width="640" height="360" frameborder="0"
						allow="autoplay; fullscreen" allowfullscreen></iframe> -->
					<img src="img/teaser-guiding.jpeg" width="640" border="0">
				</div>
<h1>Goal Navigation Pre-trained Weights</h1>
<p>We provide pre-trained weight of the DRL-based goal navigation policy, and sample inputs in a Colab notebook. <a href="https://drive.google.com/drive/u/0/folders/1yao1--XQ96aFdEihv0gWHWe8kQ23rJs7" target="_blank">Google Drive</a></p>
				<h1>Trajectory Datasets</h1>
				<p>In the paper, we compared the performance of navigation using different localization source, i.e. SLAM and localization from UWB. 10 trials were carried out with 5 trials each localization source. We hereby provided the original data (rosbags) which were recorded during the experiments. The data included tf, wheel odometry, lidar pointclouds, and UWB positioning (regardless of the localization source used in the trial). Thumbnails of side capturing the trails were added for reference as well. The experiment was conducted in a corridor with a hallway in the midpoint.</p>

				<table>
					<tr>
						<th>#</th>
						<th>Trial</th>
						<th>Rosbag</th>
						<th>Localization Source</th>
						<th>Duration (sec.)</th>
						<th></th>
					</tr>
					<tr>
						<td>1</td>
						<td>UWB 1</td>
						<td><a href="https://drive.google.com/drive/folders/1ZxoQdooYMcLimId7jMUEXInhLOAF7Xtq?usp=sharing">Link</td>
						<td>UWB Localization</td>
						<td>223</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>2</td>
						<td>UWB 2</td>
						<td><a href="https://drive.google.com/drive/folders/1UBScrsNKA3jx3BijCBSkHK3fXYF5TPra?usp=sharing">Link</td>
						<td>UWB Localization</td>
						<td>221</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>3</td>
						<td>UWB 3</td>
						<td><a href="https://drive.google.com/drive/folders/1zpTPIotETRglw5XpaH7sn6Uyw88z_0tz?usp=sharing">Link</td>
						<td>UWB Localization</td>
						<td>229</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>4</td>
						<td>UWB 4</td>
						<td><a href="https://drive.google.com/drive/folders/1ZbqJ1cdSbO_V_KGiSjQ19e04i33UTEZk?usp=sharing">Link</td>
						<td>UWB Localization</td>
						<td>219</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>5</td>
						<td>UWB 5</td>
						<td><a href="https://drive.google.com/drive/folders/1cfx2EX78BqJTONc8i1pm2SIr11eA9Vuf?usp=sharing">Link</td>
						<td>UWB Localization</td>
						<td>193</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>6</td>
						<td>SLAM 1</td>
						<td><a href="https://drive.google.com/drive/folders/1QrZqRHx45nBCMBWEq42SA9kWj2IwneL6?usp=sharing">Link</td>
						<td>SLAM (GMapping)</td>
						<td>365</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>7</td>
						<td>SLAM 2</td>
						<td><a href="https://drive.google.com/drive/folders/1nwtucEP7JknHKuWHG43kDecadIYqlyB_?usp=sharing">Link</td>
						<td>SLAM (GMapping)</td>
						<td>288</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>8</td>
						<td>SLAM 3</td>
						<td><a href="https://drive.google.com/drive/folders/1qDwfmYKAKAsV5YVZqLQRKImy6TT5J7Om?usp=sharing">Link</td>
						<td>SLAM (GMapping)</td>
						<td>331</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>9</td>
						<td>SLAM 4</td>
						<td><a href="https://drive.google.com/drive/folders/1HDmFcoeSmMmjlNvcGuxOehOSXkrebMsp?usp=sharing">Link</td>
						<td>SLAM (GMapping)</td>
						<td>284</td>
						<td><img src="" width="200"></td>
					</tr>
					<tr>
						<td>10</td>
						<td>SLAM 5</td>
						<td><a href="https://drive.google.com/drive/folders/1cMktoh1s87kRYoiI11JCoBNbonTGYqVR?usp=sharing">Link</td>
						<td>SLAM (GMapping)</td>
						<td>317</td>
						<td><img src="" width="200"></td>
					</tr>
				</table>

				<div class="clearer">&nbsp;</div>

			</div>

			<div class="footer">

				<span class="left">
					&copy; H.C. Wang
				</span>

				<span class="right"><a href="http://templates.arcsin.se/">Website template</a> by <a
						href="http://arcsin.se/">Arcsin</a></span>

				<div class="clearer"></div>

			</div>

		</div>

	</div>

</body>

</html>
