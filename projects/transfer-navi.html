<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<meta http-equiv="content-type" content="text/html; charset=UTF-8" />
	<meta name="description" content="description" />
	<meta name="keywords" content="keywords" />
	<meta name="author" content="author" />
	<style>
		table {
			font-family: arial, sans-serif;
			border-collapse: collapse;
			width: 100%;
		}

		td,
		th {
			border: 1px solid #dddddd;
			padding: 8px;
		}

		tr:nth-child(even) {
			background-color: #cdcdcd;
		}
	</style>
	<link rel="stylesheet" type="text/css" href="../default.css" media="screen" />
	<title>Nick Wang at NCTU</title>
</head>

<body>

	<div class="outer-container">

		<div class="inner-container">

			<div class="header">

				<div class="title">
					<span class="sitename"><a href="../index.html">Assistive Robotics Group</a>&nbsp;&nbsp;&nbsp;<a
							href="../index_ch.html">機器人與輔助科技實驗室</a></span>
				</div>

			</div>

			<div class="path">

				<a href="../index.html">Home</a>
				<a href="../event.html">News</a>
				<a href="../people.html">People</a>
				<a href="../robots.html">Robots</a>
				<a href="../research.html">Research</a>
				<a href="../publications.html">Publications</a>
				<a href="../courses.html">Courses</a>
				<a href="../materials.html">Materials</a>
			</div>

			<div class="blank">
				<div class="wrapper-center">
					<h0 style="text-align: center">
						Efficient Transfer Reinforcement Learning of Single Policy for Robust Perception and Resource-constraint Robot Navigation
					</h0>
					<h2>
						Po-Jui Huang, Yu-Ting Ko, Yi-Chen Teng, Yi Chen, Bory Huang, Hsueh-Cheng Wang
					</h2>
				<br><br>
				</div>
				<!--
				<div class="wrapper-center">
					<button onclick="window.open('https://github.com/ARG-NCTU/handover_grasping')"
						class="button button-gray">Interface</button>
					<button onclick="window.open('https://github.com/ARG-NCTU/handover-system')"
						class="button button-gray">System</button>
				</div>-->

				<h1>Abstract</h1>
				<p>
					Deep Reinforcement Learning (RL) has emerged as a powerful approach for enabling robots to navigate complex
					environments by learning through trial and error. However, deep RL’s broad adoption is hindered by issues like sample efficiency,
					as learning each task from scratch requires collecting vast, time-consuming, expensive data. In changing environments robots with
					limited resources may face constraints on sensing capabilities. Training a single neural network on diverse scenarios has the
					potential to amplify the learning pace and policy efficacy by leveraging shared structures, and potentially offer advantages
					when deploying on hardware-accelerated devices. This work aims to achieve robust perception from source domains of partially
					observed or noisy inputs by leveraging multi-modal sensors. The study builds upon efficient transfer learning paradigm of
					curriculum RL to achieve a single yet robust deep RL policy to target domains of navigating in changing environments or using
					a low-cost, resource-constraint robot. Extensive simulation and real-world testing under challenging scenarios demonstrates that
					the proposed method surpasses existing policies.
				</p>

				<div class="wrapper-center">
					<img src="img/transfer_navi_teaser.png" alt="teaser" height="400">
				</div>

				<h1>Appendix A : Traing curve </h1>
				<p> We devised a two-part educational program for navigation, incorporating a limited 90◦ field of view to enhance our agent's sensor capabilities.</p>
				<div class="wrapper-center">
					<img src="img/cave_90.png" alt="teaser" height="300">
				</div>
				<br>

				<h1>Appendix B :Evaluation trajectories for different ploicies in simulation </h1>
				<p> In (a), the curriculum policy πS1+S2 exhibits strong performance in both 240◦ and 90◦ scenarios, even when transitioning between LiDAR data observations with varying field of view. 
					This demonstrates the ability of our proposed curriculum policy to generalize effectively across different sensor field of views.
					In (b), our proposed curriculum policy πS1+S2 proves to be effective in achieving good results on LoCoBot using RGBD camera as observations. 
					This outcome serves as evidence that our curriculum policy can successfully generalize to various robots equipped with different sensor suites.

					<div class="wrapper-center">
					<img src="img/transfer_navi_traj.png" alt="teaser" height="300">
				</div>
				<br>
				
				<h1>Appendix C : UGV Real Robot in Our Experiment</h1>
				<p> We conducted real-world experiments with two different robots, as illustrated in (a) and (b). 
					For the robot in (a), we equipped it with a VLP-16 LiDAR and mmWave Radar as its primary sensors. 
					On the other hand, for the robot in (b), we utilized a depth sensing camera, specifically the realsense D435, as its main sensor. 
					In (c), we present our sensor tower, a comprehensive perception module housing the sensors, computing units, and power supply required for our experiments.</p>
				<div class="wrapper-center">
					<img src="img/transfer_navi_robot.png" alt="teaser" height="250">
				</div>
				


				<!--
				<h1>Video</h1>
				<p></p>
				<div class="container" align="middle">
					<iframe title="vimeo-player" src="https://player.vimeo.com/video/813752888?h=18f53125e9" width="640" height="360" frameborder="0" allowfullscreen></iframe>
				</div> -->
 			
<!--					<h1>Bibtex</h1>
				<div 
				style="background-color:rgb(212, 212, 212);
				color:rgb(0, 0, 0); 
				padding:15px;
				width: 680px;
				border: 1px solid rgb(0, 0, 0);;
				margin: 30px;">
				<p>
				@ARTICLE{zocco-2023-efficient-marine-debris , <br>
					author={Zocco, Federico and Lin, Tzu-Chieh and Huang, Ching-I and Wang, Hsueh-Cheng and Khyam, Mohammad Omar and Van, Mien}, <br>
					journal={IEEE Robotics and Automation Letters},  <br>
					title={Towards More Efficient EfficientDets and Real-Time Marine Debris Detection},  <br>
					year={2023}, <br>
					volume={8}, <br>
					number={4}, <br>
					pages={2134-2141}, <br>
					doi={10.1109/LRA.2023.3245405} <br>
				}
					<br>
				</p>
			  	</div> 

				<h1>Acknowledgments</h1>
				<p>
					This work was supported by the Natural Environment Research Council, United Kingdom [grant number NE/V008080/1] and by Taiwan’s National
					Science and Technology Council (grants 111-NU-E-A49-001-NU, 110-2221-E-A49-124, and 111-2623-E-A49-007). This work was funded in part by 
					Qualcomm through the Taiwan University Research Collaboration Project. (Corresponding author: Mien Van)
				</p>

			</div>
-->
			<div class="footer">

				<span class="left">
					&copy; H.C. Wang
				</span>

				<!-- <span class="right"><a href="http://templates.arcsin.se/">Website template</a> by <a
						href="http://arcsin.se/">Arcsin</a></span> -->

				<div class="clearer"></div>

			</div>

		</div>

	</div>

</body>

</html>
