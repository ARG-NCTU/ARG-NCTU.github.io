<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
<meta name="description" content="description"/>
<meta name="keywords" content="keywords"/> 
<meta name="author" content="author"/> 
<link rel="stylesheet" type="text/css" href="../default.css" media="screen"/>
<title>Nick Wang at NCTU</title>
</head>

<body>

<div class="outer-container">

<div class="inner-container">

	<div class="header">
		
		<div class="title">
			<span class="sitename"><a href="../index.html">Assistive Robotics Group</a>&nbsp;&nbsp;&nbsp;<a href="index_ch.html">機器人與輔助科技實驗室</a></span>
		</div>

	</div>

	<div class="path">

		<a href="../index.html">Home</a> 
		<a href="../event.html">News</a> 
		<a href="../people.html">People</a> 
		<a href="../robots.html">Robots</a> 
		<a href="../research.html">Research</a> 
		<a href="../publications.html">Publications</a>
		<a href="../courses.html">Courses</a>
		<a href="../materials.html">Materials</a>
	</div>

	<div class="blank">
		<h0>Pose-Aware Placement of Objects with Semantic Labels 
			Brandname-based Affordance Prediction and Cooperative Dual-Arm
			Active Manipulation</h0>
		<p></p>

		<h1>Abstract</h1>
		<p>
			The Amazon Picking Challenge and the Amazon Robotics Challenge have shown significant progress 
			in object picking from a cluttered scene, yet object placement remains challenging. 
			It is useful to have pose-aware placement based on human and machine readable pieces on an object. 
			For example, the \emph{brandname} of an object placed on a shelf should be facing the human customers. 
			The robotic vision challenges in the object placement task: a) the semantics and geometry of the object 
			to be placed need to be analysed jointly; b) and the occlusions among objects in a cluttered scene could 
			make it hard for proper understanding and manipulation. To overcome these challenges, we develop a pose-aware 
			placement approach by spotting the semantic labels (e.g., brandnames) of objects in a cluttered tote and 
			then carrying out a sequence of actions to place the objects on a shelf or on a conveyor with desired poses. 
			Our major contributions include 1) providing an open benchmark dataset of objects and brandnames with multi-view 
			segmentation for training and evaluations; 2) carrying out comprehensive evaluations for our brandname-based 
			fully convolutional network (FCN) that can predict the affordance and grasp to achieve pose-aware placement, 
			whose success rates decrease along with clutters; 3) showing that active manipulation with two cooperative 
			manipulators and grippers can effectively handle the occlusion of brandnames. We analyzed the success rates 
			and discussed the failure cases to provide insights for future applications. All data and benchmarks are available 
			at <a href="https://text-pick-n-place.github.io/TextPNP/">here</a>.
        </p>

		<h1>Video</h1>
		<div class="container" align="middle">
		    <iframe src="https://www.youtube.com/embed/32skA6hZa_Q" width="560" height="315" frameborder="0" allow="autoplay; fullscreen" allowfullscreen></iframe>
        </div>

        <h1>Text-PnP Dataset</h1>
        <div style="padding-left: 20px;">
			<ul type="disc">
				<li><strong>Class</strong> : 20</li>
				<li><strong>Class list</strong> : 3m, andes, cocacola, crayola, folgers, heineken, hunts, kellogg, kleenex, kotex, libava, macadamia, milo, mm, pocky, raisins, stax, swissmiss, vanish, viva</li>
				<li><strong>Image size</strong> : 640*480</li>
				<li><strong>Real</strong> : photoed by SR300</li>
				<li><strong>Virtual</strong> : generated by Unity</li>
				<li><strong>Content</strong> : </li>
				<div style="padding-left: 30px;">
					<ul type="circle">
					<li><strong>Object</strong> : include each side of object</li>
					<li><strong>BN</strong> : the brandname is labeled within the range of 45° to -45° </li>
					<li><strong>Benchmark</strong> : 10 class(3m, andes, crayola, hunts, kleenex, milo, pocky, raisins, stax, vanish)</li>
					<div style="padding-left: 40px;">
						<li><strong>Singel</strong> : 1 object per image</li>
						<li><strong>Duplicate</strong> : 2 the same objects per image</li>
						<li><strong>Multiple</strong> : 2 different objects per image</li>
						<li><strong>3 cluster</strong> : 3 objects per image</li>
						<li><strong>5 cluster</strong> : 5 objects per image</li>
						<li><strong>7 cluster</strong> : 7 objects per image</li>
					</div>
				</div>
			</ul>
			<table class="table table-bordered table-hover table-condensed" style="width: 100%">
				<tbody>
					<tr>
						<td><b>Data Type</b></td>
						<td><b>Content</b></td>
						<td><b>Blur</b></td>
						<td><b>Dataset(.tar)</b></td>
					</tr>
					<tr>
						<td>Real</td>
						<td>Objects, BN</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=1mR7ZMujgDS8iIypru7FHU1qEapluUkfL">real_data.zip</a></td>
					</tr>
					<tr>
						<td>Real</td>
						<td>benchmark - single</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=1RQ9Koc5jaJYytXWdi5L-jFVwsKeWL6_a">single.zip</a></td>
					</tr>
					<tr>
						<td>Real</td>
						<td>benchmark - duplicate</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=1akO2P5E4Zqm1glKVd-WrskV5OO3mrXUO">duplicate.zip</a></td>
					</tr>
					<tr>
						<td>Real</td>
						<td>benchmark - multiple</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=11f0YFoZ0pKB5HqTe8BAGK6AtIY03wXNv">multiple.zip</a></td>
					</tr>
					<tr>
						<td>Real</td>
						<td>benchmark - 3 cluster</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=1QDwqITAQYGlA_jP-WrYF5vsNmKqSDf-W">3_obj.zip</a></td>
					</tr>
					<tr>
						<td>Real</td>
						<td>benchmark - 5 cluster</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=13UpgV79-dsB_CuqOggnJ08gnPNuHEkli">5_obj.zip</a></td>
					</tr>
					<tr>
						<td>Real</td>
						<td>benchmark - 7 cluster</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=1O8oSXWmuKJqV_s-2gOsnNvj2Cpx8kAZE">7_obj.zip</a></td>
					</tr>
					<tr>
						<td>Virtual</td>
						<td>Object</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=1ssT32JJPMao8RsLPBHo2_r3DdvaEvRSM">virtual_object.zip</a></td>
					</tr>
					<tr>
						<td>Virtual</td>
						<td>Object</td>
						<td>Motion</td>
						<td><a href="https://drive.google.com/open?id=1gJNXuo-pf1LeDWfAjQQ_VazEWayUqGie">virtual_object_motion_blur.zip</a></td>
					</tr>
					<tr>
						<td>Virtual</td>
						<td>Object</td>
						<td>Gaussian</td>
						<td><a href="https://drive.google.com/open?id=1nIo5jVPCdQC39Y0Qp9EIPh5Nr4jB42nl">virtual_object_gaussian_blur.zip</a></td>
					</tr>
					<tr>
						<td>Virtual</td>
						<td>Object</td>
						<td>Motion + Gaussian</td>
						<td><a href="https://drive.google.com/open?id=1y1dEALOQuiXHC_Drt4qf67Xj2yNA4m4K">virtual_object_motion_gaussian_blur.zip</a></td>
					</tr>
					<tr>
						<td>Virtual</td>
						<td>BN</td>
						<td>-</td>
						<td><a href="https://drive.google.com/open?id=1GBskfqy1Six5ncoulUFwiyuo7LcPzh4c">virtual_brandname.zip</a></td>
					</tr>
				</tbody>
			</table>
		</div>

		<h1>The Paper</h1>
		<p>The project paper can be found <a href="https://arg-nctu.github.io/publications/text-pick-n-place-paper.pdf">here</a>.</p>

        <div style='overflow-x:scroll;overflow-y:hidden;width:600px;height:250px'>
			<h2>Bibtex</h2>
			<pre><code>


@article{Su-2019-IROS,
	title={Pose-Aware Placement of Objects with Semantic Labels-Brandname-based Affordance Prediction and Cooperative Dual-Arm Active Manipulation},
	author={Su, Yung-Shan and Lu, Shao-Huang and Ser, Po-Sheng and Hsu, Wei-Ting and Lai, Wei-Cheng and Xie, Biao and Huang, Hong-Ming and Lee, Teng-Yok and Chen, Hung-Wen and Yu, Lap-Fai and others},
	year={2019}
}
            </code></pre>
		</div>



		<div class="clearer">&nbsp;</div>

	</div>

	<div class="footer">

		<span class="left">
			&copy; H.C. Wang
		</span>

		<span class="right"><a href="http://templates.arcsin.se/">Website template</a> by <a href="http://arcsin.se/">Arcsin</a></span>

		<div class="clearer"></div>

	</div>

</div>

</div>

</body>

</html>
